{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cv2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cgangwar11/Coding-Practice/blob/master/practice_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fvKulXMK44V5",
        "colab_type": "code",
        "outputId": "66b3ba22-7e3a-4f11-fff4-e3832f64cb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-30 08:18:38--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 54.230.75.71, 54.230.75.21, 54.230.75.45, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|54.230.75.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip.2’\n",
            "\n",
            "\rdata.zip.2            0%[                    ]       0  --.-KB/s               \rdata.zip.2          100%[===================>]   2.75M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-03-30 08:18:39 (31.9 MB/s) - ‘data.zip.2’ saved [2882130/2882130]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H83MQHsrYzwo",
        "colab_type": "code",
        "outputId": "f4f28336-b925-4616-98ee-57a2ce5b0a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/names/Arabic.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/names/Chinese.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/names/Czech.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/names/Dutch.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xg0xcFPi47eE",
        "colab_type": "code",
        "outputId": "d5a85f3e-1f40-4e41-8e83-70f666ccf3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls data/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eng-fra.txt  names\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VMLd0QIH5NBv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing\n"
      ]
    },
    {
      "metadata": {
        "id": "GVH0_8iqQsNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch.utils.data import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJO9WV2QQcwr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RyWa5j5H5KWq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukVkVbQk8MEq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "toXkv36m5cQA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_list = glob.glob('data/names/*.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DpRWHpcG8Nvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9qf1TaJ5iYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = open(file_list[0],'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGQq-HBp5ynu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out = list(file.readlines())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ywdCdusl6Cpo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def readlines(filename):\n",
        "    out = open(filename).read().strip().split('\\n')\n",
        "    return [unicode_to_ascii(i) for i in out]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wxmmrDg27cJ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_categories = []\n",
        "names = {}\n",
        "category_to_int = {}\n",
        "for file in file_list:\n",
        "    category = file.split('/')[-1].split('.txt')[0]\n",
        "    category = category.strip().lower()\n",
        "    names[category] = readlines(file)\n",
        "    all_categories.append(category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BTZPximz9Jaw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "category_to_int = {j:i for i,j in enumerate(all_categories)}\n",
        "all_letters_to_int = {j:i for i,j in enumerate(all_letters)}\n",
        "def category_to_tensor(i):\n",
        "    out=torch.zeros((1,len(all_categories)))\n",
        "    out[0,category_to_int[i]]=1\n",
        "    return out\n",
        "\n",
        "def word_to_tensor(word):\n",
        "    out = []\n",
        "    for i in range(15):\n",
        "        try:\n",
        "            pp =np.zeros((1,len(all_letters)))\n",
        "            index = all_letters_to_int[word[i]]\n",
        "            pp[0,index]=1\n",
        "           # print(pp)\n",
        "            out.append(pp)\n",
        "        except:\n",
        "            t=np.zeros((1,len(all_letters)))\n",
        "            t[0,52]=1\n",
        "            out.append(t)\n",
        "    out=np.array(out)\n",
        "    return torch.Tensor(out).view(15,len(all_letters))\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzN13AQclVcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "33550e79-406b-4fc8-ce54-dc62d70f64c5"
      },
      "cell_type": "code",
      "source": [
        "print(all_letters_to_int)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, ' ': 52, '.': 53, ',': 54, ';': 55, \"'\": 56}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dylb1ao7jMlz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "e5263e15-2f92-4f0a-f3ab-0ffe99cc6eb4"
      },
      "cell_type": "code",
      "source": [
        "np.zeros((1,100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "9Z0ona2fiE9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6a88155-7bf8-40a7-dc4b-2ce799326386"
      },
      "cell_type": "code",
      "source": [
        "word_to_tensor('Chandan').shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 57])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "vQGC7V0nxt-4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,num_embedding,embedding_dim,hidden_size):\n",
        "        super(RNN,self).__init__()\n",
        "#         self.embedding = nn.Embedding(num_embeddings=num_embedding,embedding_dim=embedding_dim)\n",
        "        self.rnn = nn.RNN(input_size = embedding_dim,hidden_size=hidden_size)\n",
        "        self.linear = nn.Linear(hidden_size*15,len(all_categories))\n",
        "        \n",
        "    def forward(self,input):\n",
        "#         out = self.embedding(input)\n",
        "#         out = out.view(len(input),-1,int(len(all_letters)/2))\n",
        "        out,_ = self.rnn(input)\n",
        "        sh = out.shape\n",
        "        print(sh)\n",
        "#         out = out[:,-1,:]\n",
        "        out = self.linear(out)\n",
        "        return F.softmax(out)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Nq8TkRf_s3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "002c8448-b3e2-44c9-c855-2b3b54e008c1"
      },
      "cell_type": "code",
      "source": [
        "model = RNN(len(all_letters),len(all_letters),128)\n",
        "model.to(torch.device('cuda'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (rnn): RNN(57, 128)\n",
              "  (linear): Linear(in_features=1920, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "E1RqUuYU-6Yd",
        "colab_type": "code",
        "outputId": "b3f57f17-9e29-46fa-c2b7-be6899c21097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "cell_type": "code",
      "source": [
        "model(data[0][0].unsqueeze(1).to(device))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 1, 128])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-e244571e97f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-7b55a9cb48e3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         out = out[:,-1,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [15 x 128], m2: [1920 x 18] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GaQkaRq1e3ne",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pair = []\n",
        "for key,value in names.items():\n",
        "    for name in value:\n",
        "        pair.append((key,name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XBoq-7ytZu20",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NameLanguageDataset(Dataset):\n",
        "    \n",
        "    def __init__(self,pair):\n",
        "        self.source = pair\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.source)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        language,name = self.source[idx]\n",
        "        return word_to_tensor(name),category_to_int[language],name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKUPAGzNZ5Zm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = NameLanguageDataset(pair)\n",
        "params = {'batch_size': 64,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 6}\n",
        "\n",
        "generator = DataLoader(data,**params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZhOHXWYhnAG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5ec1769-85e9-46c4-cad8-3f1345f55ff4"
      },
      "cell_type": "code",
      "source": [
        "data[0][0].shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 57])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "O1UMulzdcpbf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IZlcXSkoqWxd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "los=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KSPAa8m8qfOP",
        "colab_type": "code",
        "outputId": "03e6e93e-215a-4473-97ca-e08f996c87b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1832
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda')\n",
        "#los = []\n",
        "for epoch in range(5):\n",
        "    for X,y,_ in generator:\n",
        "        X=X.view(-1,15,57)\n",
        "        \n",
        "        X,y = X.to(device),y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "      #  print(y.shape)\n",
        "       # print(y,)\n",
        "        # print(X.shape,_)\n",
        "        out = model(X)\n",
        "        \n",
        "        #print(out.shape,y.view(64,18).shape)\n",
        "        lossi = loss(out,y)\n",
        "        los.append(lossi)\n",
        "        lossi.backward()\n",
        "        optimizer.step()\n",
        "    print('hey',epoch)\n",
        "        "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "hey 0\n",
            "hey 1\n",
            "hey 2\n",
            "hey 3\n",
            "hey 4\n",
            "hey 5\n",
            "hey 6\n",
            "hey 7\n",
            "hey 8\n",
            "hey 9\n",
            "hey 10\n",
            "hey 11\n",
            "hey 12\n",
            "hey 13\n",
            "hey 14\n",
            "hey 15\n",
            "hey 16\n",
            "hey 17\n",
            "hey 18\n",
            "hey 19\n",
            "hey 20\n",
            "hey 21\n",
            "hey 22\n",
            "hey 23\n",
            "hey 24\n",
            "hey 25\n",
            "hey 26\n",
            "hey 27\n",
            "hey 28\n",
            "hey 29\n",
            "hey 30\n",
            "hey 31\n",
            "hey 32\n",
            "hey 33\n",
            "hey 34\n",
            "hey 35\n",
            "hey 36\n",
            "hey 37\n",
            "hey 38\n",
            "hey 39\n",
            "hey 40\n",
            "hey 41\n",
            "hey 42\n",
            "hey 43\n",
            "hey 44\n",
            "hey 45\n",
            "hey 46\n",
            "hey 47\n",
            "hey 48\n",
            "hey 49\n",
            "hey 50\n",
            "hey 51\n",
            "hey 52\n",
            "hey 53\n",
            "hey 54\n",
            "hey 55\n",
            "hey 56\n",
            "hey 57\n",
            "hey 58\n",
            "hey 59\n",
            "hey 60\n",
            "hey 61\n",
            "hey 62\n",
            "hey 63\n",
            "hey 64\n",
            "hey 65\n",
            "hey 66\n",
            "hey 67\n",
            "hey 68\n",
            "hey 69\n",
            "hey 70\n",
            "hey 71\n",
            "hey 72\n",
            "hey 73\n",
            "hey 74\n",
            "hey 75\n",
            "hey 76\n",
            "hey 77\n",
            "hey 78\n",
            "hey 79\n",
            "hey 80\n",
            "hey 81\n",
            "hey 82\n",
            "hey 83\n",
            "hey 84\n",
            "hey 85\n",
            "hey 86\n",
            "hey 87\n",
            "hey 88\n",
            "hey 89\n",
            "hey 90\n",
            "hey 91\n",
            "hey 92\n",
            "hey 93\n",
            "hey 94\n",
            "hey 95\n",
            "hey 96\n",
            "hey 97\n",
            "hey 98\n",
            "hey 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EjKWB0Jfr8gE",
        "colab_type": "code",
        "outputId": "d271582b-4a53-4e21-aaf0-a9a4982feb0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17634
        }
      },
      "cell_type": "code",
      "source": [
        "los\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(-0.0553, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.0567, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.0583, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.0586, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.0617, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.0634, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.0673, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.0698, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.0787, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.0869, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.1073, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.1263, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.1416, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.1527, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.1480, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.1819, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.1792, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2271, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2175, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.1996, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2738, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2988, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2665, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3410, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2650, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3452, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3145, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2475, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2872, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3608, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3013, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3863, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3599, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4233, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3946, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3469, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4179, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4524, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4995, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4211, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3383, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4074, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4523, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3783, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4653, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5252, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4122, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5072, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4228, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3414, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5134, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5387, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3899, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3762, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4429, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4238, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4282, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4286, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3526, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3387, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3499, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5329, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4725, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5079, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4631, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4332, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4151, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4767, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3880, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3884, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5108, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4938, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4804, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4922, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3870, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5710, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3577, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4638, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3698, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5088, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5259, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4167, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4973, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5727, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4802, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5263, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4500, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5111, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4672, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4174, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5290, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4985, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4490, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4501, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3598, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4509, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4351, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4490, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4508, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4217, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4670, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4496, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4198, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5743, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4674, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4376, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4653, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5275, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4067, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4973, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4996, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4380, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4348, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6827, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4381, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3429, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6827, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4220, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5282, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4812, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4968, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4376, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3765, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4977, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4690, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4690, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4846, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3583, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3915, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4673, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4355, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5130, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5471, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4357, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4702, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4667, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4517, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5635, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5013, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5170, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5447, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4861, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4361, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4396, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4858, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4673, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4205, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4514, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5019, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5306, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3589, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4522, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3745, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4204, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4397, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4864, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4402, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4053, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4208, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3627, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5763, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5611, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4095, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4869, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4368, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5026, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4365, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4051, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4988, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3476, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4993, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5498, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4565, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5030, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5148, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4097, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4255, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4991, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6235, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4411, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4412, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4675, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5035, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4369, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3793, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5348, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5194, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3905, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3905, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5924, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3905, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4420, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2972, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5044, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3799, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5460, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4266, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5300, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4677, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4114, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3803, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4991, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6138, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3593, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5205, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4273, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4116, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4834, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4212, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5151, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3808, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4057, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4589, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4745, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4213, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4902, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4215, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5151, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3589, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4528, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4681, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4685, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4906, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5305, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4750, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4682, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5150, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4752, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4525, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4992, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4755, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5621, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3907, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5066, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4757, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4525, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4058, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4601, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4446, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4998, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3824, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4685, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5149, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4762, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3438, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5075, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4838, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4296, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4682, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5232, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4610, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4370, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5234, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5236, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5236, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5777, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4302, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5083, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4927, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4685, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4461, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4463, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4619, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4219, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4375, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5306, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4219, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5558, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4375, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4935, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5872, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4625, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4061, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5406, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3594, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5622, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4785, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4372, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3283, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4007, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4061, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5099, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4839, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4683, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5310, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4995, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2971, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4059, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4527, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3903, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4168, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4636, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5103, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4997, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5105, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4637, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5262, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5466, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4639, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4372, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4454, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6089, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6087, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5620, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3748, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5890, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4954, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4684, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5153, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5932, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3907, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4332, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5112, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3241, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5269, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3866, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5467, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5152, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4375, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4491, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3438, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5116, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4060, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4375, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4996, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4219, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5623, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4650, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4372, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4806, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4807, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4375, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4807, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4964, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5276, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3904, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3750, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4653, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3751, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4996, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6059, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4811, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5279, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3751, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4375, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5592, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4840, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4684, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5281, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4969, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4813, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4996, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4372, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4346, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3748, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5595, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5467, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4217, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4060, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4816, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4660, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4972, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3906, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4660, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4349, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3750, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4661, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5465, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4998, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4350, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4685, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3726, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4840, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4350, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5131, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6380, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4195, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4373, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4061, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6381, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4196, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5289, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4529, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4061, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3748, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4978, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5309, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4822, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4685, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4666, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4372, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4979, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4198, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5466, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5153, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3436, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4199, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5292, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4373, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5778, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4824, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3750, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4217, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4356, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4842, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5761, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4513, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5293, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6090, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4513, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3750, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5606, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4373, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4826, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5294, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5295, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4514, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3109, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5451, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5154, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3890, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5154, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4047, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5608, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4061, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4217, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4685, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4685, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4047, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5153, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4984, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4685, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4672, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4516, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4998, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4673, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3267, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4048, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4829, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5467, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5610, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5610, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4986, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4830, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4373, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3124, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3437, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4529, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3893, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5154, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4986, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4362, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4529, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4831, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4675, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4529, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5612, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5299, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4363, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4373, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4207, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4217, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4831, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5612, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3593, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4363, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4832, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5310, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3593, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4061, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5613, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3583, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5301, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5457, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4208, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5310, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4364, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4989, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4989, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5779, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4521, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4833, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4061, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4052, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3750, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4052, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4998, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4842, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4209, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4365, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4365, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4209, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4521, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3594, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4061, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4842, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3741, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5146, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5622, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4990, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4834, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3897, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3741, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4522, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5771, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5154, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5615, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5154, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3585, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4998, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4991, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4373, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5154, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5935, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4217, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4373, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5147, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5310, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4061, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4991, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5304, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4842, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5304, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4842, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4835, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4679, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4523, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4211, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5467, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5935, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6872, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5468, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4998, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5304, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5460, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4217, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4211, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4523, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3905, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4523, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5148, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4367, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3274, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4680, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4055, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4842, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5461, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5712, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5461, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5149, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4993, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4993, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3906, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4842, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5774, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5149, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4837, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4524, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4212, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6092, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5624, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4212, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4837, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5305, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4525, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4056, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4681, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4993, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4212, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5468, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.2963, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5623, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4369, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4842, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4842, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5306, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4056, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4057, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3900, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4369, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5306, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5468, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5150, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5312, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4994, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4838, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4994, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5780, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5306, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3588, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5150, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3276, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4682, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5306, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4369, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5463, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3593, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3437, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4213, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4838, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4994, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4838, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4526, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5151, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4838, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4838, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4682, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5776, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5468, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4995, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4526, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4526, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5467, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5463, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4682, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5463, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5307, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4058, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4526, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5780, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4683, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5463, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3745, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5463, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4526, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4058, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3906, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5151, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4058, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5467, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4214, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5308, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4214, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5624, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4839, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4527, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5620, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3281, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4839, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5467, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3746, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4995, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3437, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4683, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4527, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4058, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5464, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4683, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5467, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3594, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5152, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4839, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5464, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4996, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3593, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4215, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4840, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5152, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3125, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4683, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5468, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4683, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4215, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5308, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4840, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4684, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4063, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6246, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4684, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4840, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4996, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5152, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5465, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3903, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5465, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5465, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5309, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5624, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5621, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4528, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3906, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5152, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4371, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4059, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3591, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4528, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3437, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5309, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4528, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4059, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4686, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4840, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4996, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5934, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4840, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5621, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3434, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4684, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4996, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5780, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4684, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4997, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.6090, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5934, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4062, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5468, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5153, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4059, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4997, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5311, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5153, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5309, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5622, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4684, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5778, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3903, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4528, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4528, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4684, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4372, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3906, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4528, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3747, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3125, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3906, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5622, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5153, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4372, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3906, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5153, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5778, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3568, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4372, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5153, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4997, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5468, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4375, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4531, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3904, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4375, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4528, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4375, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4529, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4997, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3747, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3749, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5312, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4216, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5778, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.3906, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5312, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5936, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4687, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4685, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4218, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4374, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5156, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5155, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5936, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5466, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4999, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5153, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5466, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4529, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5156, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4843, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.5312, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4530, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor(-0.4841, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "6hK4H8_XtjHd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "4934a0a5-656c-49c7-8d9a-7c819b5bf163"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(los)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f43f79560b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DEoK68J_BoVP",
        "colab_type": "code",
        "outputId": "522887d1-3dc3-4af7-efe9-2f0578b273ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "model.to(torch.device('cuda'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (rnn): RNN(57, 128)\n",
              "  (linear): Linear(in_features=128, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "MGIrlQKYpqke",
        "colab_type": "code",
        "outputId": "a73b5c72-308d-4258-fa8a-407942e8f8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "torch.zeros(5).long()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "liPcwRVno7VS",
        "colab_type": "code",
        "outputId": "b584a360-0242-4e57-d904-0d339382b09b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "torch.randint(10,(10,10))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2, 9, 0, 5, 5, 0, 0, 2, 4],\n",
              "        [8, 7, 4, 1, 9, 3, 1, 4, 9, 1],\n",
              "        [2, 1, 5, 0, 0, 5, 3, 9, 4, 6],\n",
              "        [3, 7, 2, 5, 4, 7, 0, 5, 0, 9],\n",
              "        [5, 8, 2, 8, 3, 9, 2, 5, 0, 4],\n",
              "        [2, 4, 6, 6, 6, 0, 3, 2, 4, 7],\n",
              "        [5, 2, 3, 3, 5, 3, 1, 3, 2, 1],\n",
              "        [8, 7, 6, 1, 7, 9, 8, 8, 4, 3],\n",
              "        [6, 3, 8, 8, 6, 9, 7, 5, 1, 9],\n",
              "        [4, 6, 9, 9, 2, 6, 5, 1, 9, 8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "e2sNraT8_9mi",
        "colab_type": "code",
        "outputId": "577d15d4-9146-4686-9abd-85a4c50c0fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "cell_type": "code",
      "source": [
        "model(data[0][0]),data[0][1]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-508d380728b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-876b98d342ed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#         out = self.embedding(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#         out = out.view(len(input),-1,int(len(all_letters)/2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    129\u001b[0m             raise RuntimeError(\n\u001b[1;32m    130\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 131\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0sWLEaRE_Xg1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(all_letters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ftzx-OuCzpLY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = RNN(27,5,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Kfilq5F0NrO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model(torch.LongTensor([[5,6,7,8],[10,1,2,4]])).shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}